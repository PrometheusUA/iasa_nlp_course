{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commonlit Homework Lecture 2 Andrii Shevtsov\n",
    "\n",
    "In the previous home task, my scores for LightGBM model were:\n",
    "\n",
    "Validation = `0.76897`\n",
    "\n",
    "Leaderboard:\n",
    "![Old lightgbm leaderboard scores](https://i.imgur.com/QLtgeZV.png)\n",
    "\n",
    "For the linear regression, the validation score was ≈ `0.8`.\n",
    "\n",
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: optuna in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from lightgbm) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from lightgbm) (1.11.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (1.12.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (2.0.21)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: cmaes>=0.10.0 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from optuna) (0.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.8.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\andrii\\anaconda3\\envs\\iasa_nlp_env\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import gensim\n",
    "import optuna\n",
    "import string\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARIES_TRAIN_FILE = '../../data/commonlit_evaluate_student_summaries/summaries_train.csv'\n",
    "SUMMARIES_TEST_FILE = '../../data/commonlit_evaluate_student_summaries/summaries_test.csv'\n",
    "PROMPTS_TRAIN_FILE = '../../data/commonlit_evaluate_student_summaries/prompts_train.csv'\n",
    "PROMPTS_TEST_FILE = '../../data/commonlit_evaluate_student_summaries/prompts_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets and competition description\n",
    "\n",
    "The dataset comprises about 24,000 summaries written by students in grades 3-12 of passages on a variety of topics and genres. These summaries have been assigned scores for both content and wording. The goal of the competition is to predict content and wording scores for summaries on unseen topics.\n",
    "\n",
    "### Goal of the Competition\n",
    "\n",
    "The goal of this competition is to assess the quality of summaries written by students in grades 3-12. You'll build a model that evaluates how well a student represents the main idea and details of a source text, as well as the clarity, precision, and fluency of the language used in the summary. You'll have access to a collection of real student summaries to train your model.\n",
    "\n",
    "Your work will assist teachers in evaluating the quality of student work and also help learning platforms provide immediate feedback to students.\n",
    "\n",
    "### File and Field Information\n",
    "\n",
    "- **summaries_train.csv** - Summaries in the training set.\n",
    "    - `student_id` - The ID of the student writer.\n",
    "    - `prompt_id` - The ID of the prompt which links to the prompt file.\n",
    "    - `text` - The full text of the student's summary.\n",
    "    - `content` - The content score for the summary. The first target.\n",
    "    - `wording` - The wording score for the summary. The second target.\n",
    "- **summaries_test.csv** - Summaries in the test set. Contains all fields above except content and wording.\n",
    "- **prompts_train.csv** - The four training set prompts. Each prompt comprises the complete summarization assignment given to students.\n",
    "    - `prompt_id` - The ID of the prompt which links to the summaries file.\n",
    "    - `prompt_question` - The specific question the students are asked to respond to.\n",
    "    - `prompt_title` - A short-hand title for the prompt.\n",
    "    - `prompt_text` - The full prompt text.\n",
    "- **prompts_test.csv** - The test set prompts. Contains the same fields as above. The prompts here are only an example. The full test set has a large number of prompts. **The train / public test / private test splits do not share any prompts.**\n",
    "- **sample_submission.csv** - A submission file in the correct format. See the Evaluation page for details.\n",
    "\n",
    "This is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. The full test set comprises about 17,000 summaries from a large number of prompts.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Submissions are scored using MCRMSE, mean columnwise root mean squared error:\n",
    "\n",
    "![MCRMSE](https://latex.codecogs.com/png.latex?\\dpi{150}&space;\\fn_phv&space;\\text{MCRMSE}&space;=&space;\\frac{1}{m}&space;\\sum_{j=1}^{m}&space;\\sqrt{\\frac{1}{n}&space;\\sum_{i=1}^{n}&space;(y_{ij}&space;-&space;\\hat{y}_{ij})^2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train_df = pd.read_csv(SUMMARIES_TRAIN_FILE)\n",
    "summaries_test_df = pd.read_csv(SUMMARIES_TEST_FILE)\n",
    "prompts_train_df = pd.read_csv(PROMPTS_TRAIN_FILE)\n",
    "prompts_test_df = pd.read_csv(PROMPTS_TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording  \n",
       "0  0.205683  0.380538  \n",
       "1 -0.548304  0.506755  \n",
       "2  3.128928  4.231226  \n",
       "3 -0.210614 -0.471415  \n",
       "4  3.272894  3.219757  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "EDA would have been here, but for this notebook I see no value in repeating or improving it from the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Probably, hard preprocessing with stemming / lemmatization and soft preprocessing will be beneficial for different kind of vectorization techniques, text-based features and final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'good', 'bad', 'people']) #stopwords extended a bit\n",
    "def preprocess_hard_base(text, join_back=True):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        # Stop Words Cleaning\n",
    "        if (\n",
    "            token not in gensim.parsing.preprocessing.STOPWORDS and \n",
    "            token not in stop_words\n",
    "        ):\n",
    "            result.append(token)\n",
    "    if join_back:\n",
    "        result = \" \".join(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hard_stemming(text, join_back=True, stemmer = PorterStemmer()):\n",
    "    tokens = preprocess_hard_base(text, join_back=False)\n",
    "    \n",
    "    result = [stemmer.stem(word) for word in tokens]\n",
    "    if join_back:\n",
    "        result = \" \".join(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrii\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Andrii\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess_hard_lemmatizing(text, join_back=True, lemmatizer = WordNetLemmatizer()):\n",
    "    tokens = preprocess_hard_base(text, join_back=False)\n",
    "    \n",
    "    result = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    if join_back:\n",
    "        result = \" \".join(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare two NLTK stemmers: Porter Stemmer and Snowball Stemmer; and WordNet Lemmatizer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter    : exampl compani organ countri name steve creat appl steve creat appl definit differ sentenc embed differ score classifi news articl topic case detriment ner task speech tag compani name like beauti sentiment analysi task exampl go bigger valu furi class score simpl go assum preprocess convert consecut punctuat sign singl sequenc sequenc text gener like chatgpt instruct llm creat text lowercas stem lemmat train preprocess common nlp sens\n",
      "\n",
      "Snowball  : exampl compani organ countri name steve creat appl steve creat appl definit differ sentenc embed differ score classifi news articl topic case detriment ner task speech tag compani name like beauti sentiment analysi task exampl go bigger valu furi class score simpl go assum preprocess convert consecut punctuat sign singl sequenc sequenc text generat like chatgpt instruct llms creat text lowercas stem lemmat train preprocess common nlp sens\n",
      "\n",
      "Lemmatizer: example company organization country name steve created apple steve created apple definitely different sentence embeddings different score classifier news article topic case detrimental ner task speech tagging company named like beautiful sentiment analysis task example going bigger value fury class score simple going assuming preprocessing convert consecutive punctuation sign single sequence sequence text generation like chatgpt instruction llm creating text lowercase stemmed lemmatized train preprocessing common nlp sense\n"
     ]
    }
   ],
   "source": [
    "original_text = \"\"\"For example:\n",
    "• The company / organization / country / people names. \"Steve has created Apple\" and \"Steve has created an apple\" should definitely have different sentence embeddings and different scores in the classifier of news article topics. Also, in this case, it can be detrimental for NER tasks and even part of speech tagging (if the company is named something like \"Beautiful\").\n",
    "• Sentiment analysis tasks. For example, \"WHAT IS GOING ON???\" should have a bigger value for the \"fury\" class score than the simple \"What is going on?\" (assuming your preprocessing also converts consecutive punctuation signs to a single one).\n",
    "• Sequence to sequence text generation. People wouldn't like ChatGPT and other instruction LLMs so much if they were creating text in lowercase (and even more if it was stemmed or lemmatized). That's why it should train almost without preprocessing in common NLP sense.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Porter    :\", preprocess_hard_stemming(original_text))\n",
    "print()\n",
    "print(\"Snowball  :\", preprocess_hard_stemming(original_text, stemmer=SnowballStemmer(\"english\")))\n",
    "print()\n",
    "print(\"Lemmatizer:\", preprocess_hard_lemmatizing(original_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only differences between stemmers are: \n",
    "- generation -> gener / generat; \n",
    "- LLMs -> llm / llms.\n",
    "\n",
    "In most cases it should be unimportant, what stemmer to use. Let's try PorterStemmer as it's tokens are smaller sometimes.\n",
    "\n",
    "Lemmatizer words are much better and more accurate, but it should require more computations to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processing time is: 4.924031734466553 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "summaries_train_df['text_hard_preprocessed_stemmed'] = summaries_train_df['text'].apply(preprocess_hard_stemming)\n",
    "print(\"Total processing time is:\", time() - start_time, \"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processing time is: 1.721034288406372 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "summaries_train_df['text_hard_preprocessed_lemmatized'] = summaries_train_df['text'].apply(preprocess_hard_lemmatizing)\n",
    "print(\"Total processing time is:\", time() - start_time, \"secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizer somehow worked faster then stemmer. Interesting...\n",
    "\n",
    "> **TODO**: refactor stemmer and lemmatizer preprocessing functions to a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_dots(text):\n",
    "    # Collapse sequential dots\n",
    "    input = re.sub(\"\\.+\", \".\", text)\n",
    "    # Collapse dots separated by whitespaces\n",
    "    all_collapsed = False\n",
    "    while not all_collapsed:\n",
    "        output = re.sub(r\"\\.(( )*)\\.\", \".\", text)\n",
    "        all_collapsed = input == output\n",
    "        input = output\n",
    "    return output\n",
    "\n",
    "# Check how it will influence different ML models\n",
    "def process_soft(text):\n",
    "    if isinstance(text, str):\n",
    "        text = \" \".join(tokenize.sent_tokenize(text))\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        text = re.sub(r\"\\n+\", \". \", text)\n",
    "        for symb in [\"!\", \",\", \":\", \";\", \"?\"]:\n",
    "            text = re.sub(rf\"\\{symb}\\.\", symb, text)\n",
    "        text = re.sub(\"[^а-яА-Яa-zA-Z0-9!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~ё]+\", \" \", text)\n",
    "        text = re.sub(r\"#\\S+\", \"\", text)\n",
    "        text = collapse_dots(text)\n",
    "        text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processing time is: 0.8830337524414062 secs\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "summaries_train_df['text_soft_preprocessed'] = summaries_train_df['text'].apply(process_soft)\n",
    "print(\"Total processing time is:\", time() - start_time, \"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>text_hard_preprocessed_stemmed</th>\n",
       "      <th>text_hard_preprocessed_lemmatized</th>\n",
       "      <th>text_soft_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>wave experimentto react new leader govern gain...</td>\n",
       "      <td>wave experimentto reacted new leader governmen...</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>rub soda smell away wouldnt smell meat toss fl...</td>\n",
       "      <td>rub soda smell away wouldnt smell meat tossed ...</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>egypt occup social class involv day day live i...</td>\n",
       "      <td>egypt occupation social class involved day day...</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>highest class pharaoh god nd highest class gon...</td>\n",
       "      <td>highest class pharaoh god nd highest class gon...</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>wave develop rapidli student genuinli believ b...</td>\n",
       "      <td>wave developed rapidly student genuinly believ...</td>\n",
       "      <td>The Third Wave developed rapidly because the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>sort chemic concoct meat fine shown quot mirac...</td>\n",
       "      <td>sort chemical concoction meat fine shown quote...</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ffc34d056498</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The lowest classes are slaves and farmers slav...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>lowest class slave farmer slave taken war farm...</td>\n",
       "      <td>lowest class slave farmer slave taken war farm...</td>\n",
       "      <td>The lowest classes are slaves and farmers slav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ffd1576d2e1b</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>they sorta made people start workin...</td>\n",
       "      <td>-1.408180</td>\n",
       "      <td>-0.493603</td>\n",
       "      <td>sorta start work structour they barley got pai...</td>\n",
       "      <td>sorta start working structour theyed barley go...</td>\n",
       "      <td>they sorta made people start working on the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ffe4a98093b2</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>An ideal tragety has three elements that make ...</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "      <td>ideal trageti element ideal start great traged...</td>\n",
       "      <td>ideal tragety element ideal start great traged...</td>\n",
       "      <td>An ideal tragety has three elements that make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "      <td>meat smell sour rub soda away smell sell rot m...</td>\n",
       "      <td>meat smell sour rub soda away smell sell rotti...</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     000e8c3c7ddb    814d6b   \n",
       "1     0020ae56ffbf    ebad26   \n",
       "2     004e978e639e    3b9047   \n",
       "3     005ab0199905    3b9047   \n",
       "4     0070c9e7af47    814d6b   \n",
       "...            ...       ...   \n",
       "7160  ff7c7e70df07    ebad26   \n",
       "7161  ffc34d056498    3b9047   \n",
       "7162  ffd1576d2e1b    3b9047   \n",
       "7163  ffe4a98093b2    39c16e   \n",
       "7164  fffbccfd8a08    ebad26   \n",
       "\n",
       "                                                   text   content   wording  \\\n",
       "0     The third wave was an experimentto see how peo...  0.205683  0.380538   \n",
       "1     They would rub it up with soda to make the sme... -0.548304  0.506755   \n",
       "2     In Egypt, there were many occupations and soci...  3.128928  4.231226   \n",
       "3     The highest class was Pharaohs these people we... -0.210614 -0.471415   \n",
       "4     The Third Wave developed  rapidly because the ...  3.272894  3.219757   \n",
       "...                                                 ...       ...       ...   \n",
       "7160  They used all sorts of chemical concoctions to...  0.205683  0.380538   \n",
       "7161  The lowest classes are slaves and farmers slav... -0.308448  0.048171   \n",
       "7162             they sorta made people start workin... -1.408180 -0.493603   \n",
       "7163  An ideal tragety has three elements that make ... -0.393310  0.627128   \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742   \n",
       "\n",
       "                         text_hard_preprocessed_stemmed  \\\n",
       "0     wave experimentto react new leader govern gain...   \n",
       "1     rub soda smell away wouldnt smell meat toss fl...   \n",
       "2     egypt occup social class involv day day live i...   \n",
       "3     highest class pharaoh god nd highest class gon...   \n",
       "4     wave develop rapidli student genuinli believ b...   \n",
       "...                                                 ...   \n",
       "7160  sort chemic concoct meat fine shown quot mirac...   \n",
       "7161  lowest class slave farmer slave taken war farm...   \n",
       "7162  sorta start work structour they barley got pai...   \n",
       "7163  ideal trageti element ideal start great traged...   \n",
       "7164  meat smell sour rub soda away smell sell rot m...   \n",
       "\n",
       "                      text_hard_preprocessed_lemmatized  \\\n",
       "0     wave experimentto reacted new leader governmen...   \n",
       "1     rub soda smell away wouldnt smell meat tossed ...   \n",
       "2     egypt occupation social class involved day day...   \n",
       "3     highest class pharaoh god nd highest class gon...   \n",
       "4     wave developed rapidly student genuinly believ...   \n",
       "...                                                 ...   \n",
       "7160  sort chemical concoction meat fine shown quote...   \n",
       "7161  lowest class slave farmer slave taken war farm...   \n",
       "7162  sorta start working structour theyed barley go...   \n",
       "7163  ideal tragety element ideal start great traged...   \n",
       "7164  meat smell sour rub soda away smell sell rotti...   \n",
       "\n",
       "                                 text_soft_preprocessed  \n",
       "0     The third wave was an experimentto see how peo...  \n",
       "1     They would rub it up with soda to make the sme...  \n",
       "2     In Egypt, there were many occupations and soci...  \n",
       "3     The highest class was Pharaohs these people we...  \n",
       "4     The Third Wave developed rapidly because the s...  \n",
       "...                                                 ...  \n",
       "7160  They used all sorts of chemical concoctions to...  \n",
       "7161  The lowest classes are slaves and farmers slav...  \n",
       "7162  they sorta made people start working on the st...  \n",
       "7163  An ideal tragety has three elements that make ...  \n",
       "7164  The meat would smell sour but the would \"rub i...  \n",
       "\n",
       "[7165 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>prompt_question_hard_preprocessed_stemmed</th>\n",
       "      <th>prompt_title_hard_preprocessed_stemmed</th>\n",
       "      <th>prompt_text_hard_preprocessed_stemmed</th>\n",
       "      <th>prompt_question_hard_preprocessed_lemmatized</th>\n",
       "      <th>prompt_title_hard_preprocessed_lemmatized</th>\n",
       "      <th>prompt_text_hard_preprocessed_lemmatized</th>\n",
       "      <th>prompt_question_soft_preprocessed</th>\n",
       "      <th>prompt_title_soft_preprocessed</th>\n",
       "      <th>prompt_text_soft_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>summar element ideal tragedi describ aristotl</td>\n",
       "      <td>tragedi</td>\n",
       "      <td>chapter sequel said proceed consid poet aim av...</td>\n",
       "      <td>summarize element ideal tragedy described aris...</td>\n",
       "      <td>tragedy</td>\n",
       "      <td>chapter sequel said proceed consider poet aim ...</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 . As the sequel to what has already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>complet sentenc summar structur ancient egypti...</td>\n",
       "      <td>egyptian social structur</td>\n",
       "      <td>egyptian societi structur like pyramid god ra ...</td>\n",
       "      <td>complete sentence summarize structure ancient ...</td>\n",
       "      <td>egyptian social structure</td>\n",
       "      <td>egyptian society structured like pyramid god r...</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>summar wave develop short period time experi end</td>\n",
       "      <td>wave</td>\n",
       "      <td>background wave experi took place cubberley hi...</td>\n",
       "      <td>summarize wave developed short period time exp...</td>\n",
       "      <td>wave</td>\n",
       "      <td>background wave experiment took place cubberle...</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background . The Third Wave experiment took pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>summar way factori cover spoil meat cite evid ...</td>\n",
       "      <td>excerpt jungl</td>\n",
       "      <td>member trim beef canneri work sausag factori f...</td>\n",
       "      <td>summarize way factory cover spoiled meat cite ...</td>\n",
       "      <td>excerpt jungle</td>\n",
       "      <td>member trimming beef cannery working sausage f...</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "1  Egyptian society was structured like a pyramid...   \n",
       "2  Background \\r\\nThe Third Wave experiment took ...   \n",
       "3  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "           prompt_question_hard_preprocessed_stemmed  \\\n",
       "0      summar element ideal tragedi describ aristotl   \n",
       "1  complet sentenc summar structur ancient egypti...   \n",
       "2   summar wave develop short period time experi end   \n",
       "3  summar way factori cover spoil meat cite evid ...   \n",
       "\n",
       "  prompt_title_hard_preprocessed_stemmed  \\\n",
       "0                                tragedi   \n",
       "1               egyptian social structur   \n",
       "2                                   wave   \n",
       "3                          excerpt jungl   \n",
       "\n",
       "               prompt_text_hard_preprocessed_stemmed  \\\n",
       "0  chapter sequel said proceed consid poet aim av...   \n",
       "1  egyptian societi structur like pyramid god ra ...   \n",
       "2  background wave experi took place cubberley hi...   \n",
       "3  member trim beef canneri work sausag factori f...   \n",
       "\n",
       "        prompt_question_hard_preprocessed_lemmatized  \\\n",
       "0  summarize element ideal tragedy described aris...   \n",
       "1  complete sentence summarize structure ancient ...   \n",
       "2  summarize wave developed short period time exp...   \n",
       "3  summarize way factory cover spoiled meat cite ...   \n",
       "\n",
       "  prompt_title_hard_preprocessed_lemmatized  \\\n",
       "0                                   tragedy   \n",
       "1                 egyptian social structure   \n",
       "2                                      wave   \n",
       "3                            excerpt jungle   \n",
       "\n",
       "            prompt_text_hard_preprocessed_lemmatized  \\\n",
       "0  chapter sequel said proceed consider poet aim ...   \n",
       "1  egyptian society structured like pyramid god r...   \n",
       "2  background wave experiment took place cubberle...   \n",
       "3  member trimming beef cannery working sausage f...   \n",
       "\n",
       "                   prompt_question_soft_preprocessed  \\\n",
       "0  Summarize at least 3 elements of an ideal trag...   \n",
       "1  In complete sentences, summarize the structure...   \n",
       "2  Summarize how the Third Wave developed over su...   \n",
       "3  Summarize the various ways the factory would u...   \n",
       "\n",
       "  prompt_title_soft_preprocessed  \\\n",
       "0                     On Tragedy   \n",
       "1      Egyptian Social Structure   \n",
       "2                 The Third Wave   \n",
       "3        Excerpt from The Jungle   \n",
       "\n",
       "                       prompt_text_soft_preprocessed  \n",
       "0  Chapter 13 . As the sequel to what has already...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background . The Third Wave experiment took pl...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train_df['prompt_question_hard_preprocessed_stemmed'] = prompts_train_df['prompt_question'].apply(preprocess_hard_stemming)\n",
    "prompts_train_df['prompt_title_hard_preprocessed_stemmed'] = prompts_train_df['prompt_title'].apply(preprocess_hard_stemming)\n",
    "prompts_train_df['prompt_text_hard_preprocessed_stemmed'] = prompts_train_df['prompt_text'].apply(preprocess_hard_stemming)\n",
    "\n",
    "prompts_train_df['prompt_question_hard_preprocessed_lemmatized'] = prompts_train_df['prompt_question'].apply(preprocess_hard_lemmatizing)\n",
    "prompts_train_df['prompt_title_hard_preprocessed_lemmatized'] = prompts_train_df['prompt_title'].apply(preprocess_hard_lemmatizing)\n",
    "prompts_train_df['prompt_text_hard_preprocessed_lemmatized'] = prompts_train_df['prompt_text'].apply(preprocess_hard_lemmatizing)\n",
    "\n",
    "prompts_train_df['prompt_question_soft_preprocessed'] = prompts_train_df['prompt_question'].apply(process_soft)\n",
    "prompts_train_df['prompt_title_soft_preprocessed'] = prompts_train_df['prompt_title'].apply(process_soft)\n",
    "prompts_train_df['prompt_text_soft_preprocessed'] = prompts_train_df['prompt_text'].apply(process_soft)\n",
    "\n",
    "prompts_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from the Commonlit authors\n",
    "\n",
    "From https://www.kaggle.com/code/gusthema/commonlit-evaluate-student-summaries-w-tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the stop words in the text.\n",
    "def count_stopwords(text: str) -> int:\n",
    "    stopword_list = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    stopwords_count = sum(1 for word in words if word.lower() in stopword_list)\n",
    "    return stopwords_count\n",
    "\n",
    "# Count the punctuations in the text.\n",
    "# punctuation_set -> !\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~\n",
    "def count_punctuation(text: str) -> int:\n",
    "    punctuation_set = set(string.punctuation)\n",
    "    punctuation_count = sum(1 for char in text if char in punctuation_set)\n",
    "    return punctuation_count\n",
    "\n",
    "# Count the digits in the text.\n",
    "def count_numbers(text: str) -> int:\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    numbers_count = len(numbers)\n",
    "    return numbers_count\n",
    "\n",
    "# This function applies all the above preprocessing functions on a text feature.\n",
    "def streamlit_feature_engineer(dataframe: pd.DataFrame, feature: str = 'text', preprocessed_hard: bool = False) -> pd.DataFrame:\n",
    "    dataframe[f'{feature}_word_cnt'] = dataframe[feature].apply(lambda x: len(x.split(' ')))\n",
    "    dataframe[f'{feature}_length'] = dataframe[feature].apply(lambda x: len(x))\n",
    "    if not preprocessed_hard:\n",
    "        dataframe[f'{feature}_stopword_cnt'] = dataframe[feature].apply(lambda x: count_stopwords(x))\n",
    "        dataframe[f'{feature}_punct_cnt'] = dataframe[feature].apply(lambda x: count_punctuation(x))\n",
    "        dataframe[f'{feature}_number_cnt'] = dataframe[feature].apply(lambda x: count_numbers(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train_df = streamlit_feature_engineer(summaries_train_df)\n",
    "summaries_train_df = streamlit_feature_engineer(summaries_train_df, feature = \"text_hard_preprocessed_stemmed\", preprocessed_hard=True)\n",
    "summaries_train_df = streamlit_feature_engineer(summaries_train_df, feature = \"text_hard_preprocessed_lemmatized\", preprocessed_hard=True)\n",
    "summaries_train_df = streamlit_feature_engineer(summaries_train_df, feature = \"text_soft_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>text_hard_preprocessed_stemmed</th>\n",
       "      <th>text_hard_preprocessed_lemmatized</th>\n",
       "      <th>text_soft_preprocessed</th>\n",
       "      <th>text_word_cnt</th>\n",
       "      <th>text_length</th>\n",
       "      <th>...</th>\n",
       "      <th>text_hard_preprocessed_stemmed_word_cnt</th>\n",
       "      <th>text_hard_preprocessed_stemmed_length</th>\n",
       "      <th>text_hard_preprocessed_lemmatized_word_cnt</th>\n",
       "      <th>text_hard_preprocessed_lemmatized_length</th>\n",
       "      <th>text_soft_preprocessed_word_cnt</th>\n",
       "      <th>text_soft_preprocessed_length</th>\n",
       "      <th>text_soft_preprocessed_stopword_cnt</th>\n",
       "      <th>text_soft_preprocessed_punct_cnt</th>\n",
       "      <th>text_soft_preprocessed_number_cnt</th>\n",
       "      <th>prompt_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>wave experimentto react new leader govern gain...</td>\n",
       "      <td>wave experimentto reacted new leader governmen...</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>61</td>\n",
       "      <td>346</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>173</td>\n",
       "      <td>28</td>\n",
       "      <td>201</td>\n",
       "      <td>61</td>\n",
       "      <td>346</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>rub soda smell away wouldnt smell meat toss fl...</td>\n",
       "      <td>rub soda smell away wouldnt smell meat tossed ...</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>52</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "      <td>52</td>\n",
       "      <td>244</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>egypt occup social class involv day day live i...</td>\n",
       "      <td>egypt occupation social class involved day day...</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>235</td>\n",
       "      <td>1370</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>638</td>\n",
       "      <td>101</td>\n",
       "      <td>706</td>\n",
       "      <td>235</td>\n",
       "      <td>1370</td>\n",
       "      <td>98</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>highest class pharaoh god nd highest class gon...</td>\n",
       "      <td>highest class pharaoh god nd highest class gon...</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>25</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>89</td>\n",
       "      <td>14</td>\n",
       "      <td>95</td>\n",
       "      <td>25</td>\n",
       "      <td>157</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>wave develop rapidli student genuinli believ b...</td>\n",
       "      <td>wave developed rapidly student genuinly believ...</td>\n",
       "      <td>The Third Wave developed rapidly because the s...</td>\n",
       "      <td>206</td>\n",
       "      <td>1225</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>581</td>\n",
       "      <td>87</td>\n",
       "      <td>658</td>\n",
       "      <td>203</td>\n",
       "      <td>1222</td>\n",
       "      <td>92</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id prompt_id                                               text  \\\n",
       "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n",
       "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n",
       "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n",
       "3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n",
       "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n",
       "\n",
       "    content   wording                     text_hard_preprocessed_stemmed  \\\n",
       "0  0.205683  0.380538  wave experimentto react new leader govern gain...   \n",
       "1 -0.548304  0.506755  rub soda smell away wouldnt smell meat toss fl...   \n",
       "2  3.128928  4.231226  egypt occup social class involv day day live i...   \n",
       "3 -0.210614 -0.471415  highest class pharaoh god nd highest class gon...   \n",
       "4  3.272894  3.219757  wave develop rapidli student genuinli believ b...   \n",
       "\n",
       "                   text_hard_preprocessed_lemmatized  \\\n",
       "0  wave experimentto reacted new leader governmen...   \n",
       "1  rub soda smell away wouldnt smell meat tossed ...   \n",
       "2  egypt occupation social class involved day day...   \n",
       "3  highest class pharaoh god nd highest class gon...   \n",
       "4  wave developed rapidly student genuinly believ...   \n",
       "\n",
       "                              text_soft_preprocessed  text_word_cnt  \\\n",
       "0  The third wave was an experimentto see how peo...             61   \n",
       "1  They would rub it up with soda to make the sme...             52   \n",
       "2  In Egypt, there were many occupations and soci...            235   \n",
       "3  The highest class was Pharaohs these people we...             25   \n",
       "4  The Third Wave developed rapidly because the s...            206   \n",
       "\n",
       "   text_length  ...  text_hard_preprocessed_stemmed_word_cnt  \\\n",
       "0          346  ...                                       28   \n",
       "1          244  ...                                       14   \n",
       "2         1370  ...                                      101   \n",
       "3          157  ...                                       14   \n",
       "4         1225  ...                                       87   \n",
       "\n",
       "   text_hard_preprocessed_stemmed_length  \\\n",
       "0                                    173   \n",
       "1                                     80   \n",
       "2                                    638   \n",
       "3                                     89   \n",
       "4                                    581   \n",
       "\n",
       "   text_hard_preprocessed_lemmatized_word_cnt  \\\n",
       "0                                          28   \n",
       "1                                          14   \n",
       "2                                         101   \n",
       "3                                          14   \n",
       "4                                          87   \n",
       "\n",
       "   text_hard_preprocessed_lemmatized_length  text_soft_preprocessed_word_cnt  \\\n",
       "0                                       201                               61   \n",
       "1                                        82                               52   \n",
       "2                                       706                              235   \n",
       "3                                        95                               25   \n",
       "4                                       658                              203   \n",
       "\n",
       "   text_soft_preprocessed_length  text_soft_preprocessed_stopword_cnt  \\\n",
       "0                            346                                   25   \n",
       "1                            244                                   30   \n",
       "2                           1370                                   98   \n",
       "3                            157                                   11   \n",
       "4                           1222                                   92   \n",
       "\n",
       "   text_soft_preprocessed_punct_cnt  text_soft_preprocessed_number_cnt  \\\n",
       "0                                 3                                  0   \n",
       "1                                 2                                  0   \n",
       "2                                38                                  0   \n",
       "3                                 6                                  2   \n",
       "4                                30                                  3   \n",
       "\n",
       "   prompt_i  \n",
       "0         2  \n",
       "1         3  \n",
       "2         1  \n",
       "3         1  \n",
       "4         2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_ids_to_is = {prompt_id: i for i, prompt_id in zip(prompts_train_df.index, prompts_train_df['prompt_id'])}\n",
    "summaries_train_df['prompt_i'] = summaries_train_df['prompt_id'].apply(lambda prompt_id: prompts_ids_to_is[prompt_id])\n",
    "summaries_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Let's use Ridge regression and LightGBM again, but include several improvements, like:\n",
    "- Separate models for each of two metrics.\n",
    "- Different vectorization techniques performed for all the dataset.\n",
    "- Different preprocessing variants evaluated.\n",
    "- Cosine similarity of all the prompts fields and summaries instead of merged prompts fields and summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_pipeline_evaluation(alpha,\n",
    "                              features: list,\n",
    "                              features_to_scale: list,\n",
    "                              target : str=\"wording\", \n",
    "                              vectorizer=TfidfVectorizer(\n",
    "                                    analyzer='word',\n",
    "                                    stop_words='english',\n",
    "                                    ngram_range=(1, 3),\n",
    "                                    lowercase=True,\n",
    "                                    min_df=1,\n",
    "                                    max_features=30000\n",
    "                                ),\n",
    "                              vectorizer_feature: str = \"text\",\n",
    "                              prompt_processed_features: dict = {\n",
    "                                  'prompt_question': 'prompt_question',\n",
    "                                  'prompt_title': 'prompt_title',\n",
    "                                  'prompt_text': 'prompt_text'\n",
    "                              },\n",
    "                              verbose=False):\n",
    "    \n",
    "    metrics_lists={'train': [], 'val': []}\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Ridge starting, alpha={alpha}\")\n",
    "    \n",
    "    for i in tqdm(range(len(prompts_train_df))):\n",
    "        test_prompt_id = prompts_train_df.loc[i, 'prompt_id']\n",
    "        summaries_train, summaries_val = summaries_train_df[~(summaries_train_df['prompt_id'] == test_prompt_id)], summaries_train_df[summaries_train_df['prompt_id'] == test_prompt_id]\n",
    "\n",
    "        X_train, y_train = summaries_train.loc[:, ['prompt_i', *features]], summaries_train.loc[:, target]\n",
    "        X_val, y_val = summaries_val.loc[:, ['prompt_i', *features]], summaries_val.loc[:, target]\n",
    "\n",
    "        vectorizer = vectorizer.fit(X_train[vectorizer_feature])\n",
    "        train_summaries_vectors = vectorizer.transform(X_train[vectorizer_feature])\n",
    "        val_summaries_vectors = vectorizer.transform(X_val[vectorizer_feature])\n",
    "        \n",
    "        prompts_texts_vectors = vectorizer.transform(prompts_train_df[prompt_processed_features['prompt_text']])\n",
    "        prompts_titles_vectors = vectorizer.transform(prompts_train_df[prompt_processed_features['prompt_title']])\n",
    "        prompts_questions_vectors = vectorizer.transform(prompts_train_df[prompt_processed_features['prompt_question']])\n",
    "\n",
    "        scaler = RobustScaler().fit(X_train[features_to_scale])\n",
    "        X_train[features_to_scale] = scaler.transform(X_train[features_to_scale])\n",
    "        X_val[features_to_scale] = scaler.transform(X_val[features_to_scale])\n",
    "\n",
    "        y_scaler = RobustScaler().fit(y_train.to_numpy().reshape(-1, 1))\n",
    "        y_train_scaled = y_scaler.transform(y_train.to_numpy().reshape(-1, 1))\n",
    "\n",
    "        cosine_scores_train_prompts_texts = 1 - spatial.distance.cosine(prompts_texts_vectors[X_train['prompt_i']], train_summaries_vectors).reshape(-1, 1)\n",
    "        cosine_scores_val_prompts_texts = 1 - spatial.distance.cosine(prompts_texts_vectors[X_val['prompt_i']], val_summaries_vectors).reshape(-1, 1)\n",
    "        \n",
    "        cosine_scores_train_prompts_titles = 1 - spatial.distance.cosine(prompts_titles_vectors[X_train['prompt_i']], train_summaries_vectors).reshape(-1, 1)\n",
    "        cosine_scores_val_prompts_titles = 1 - spatial.distance.cosine(prompts_titles_vectors[X_val['prompt_i']], val_summaries_vectors).reshape(-1, 1)\n",
    "        \n",
    "        cosine_scores_train_prompts_questions = 1 - spatial.distance.cosine(prompts_questions_vectors[X_train['prompt_i']], train_summaries_vectors).reshape(-1, 1)\n",
    "        cosine_scores_val_prompts_questions = 1 - spatial.distance.cosine(prompts_questions_vectors[X_val['prompt_i']], val_summaries_vectors).reshape(-1, 1)\n",
    "\n",
    "        X_train = sparse.hstack((\n",
    "            train_summaries_vectors,\n",
    "            sparse.coo_matrix(cosine_scores_train_prompts_texts),\n",
    "            sparse.coo_matrix(cosine_scores_train_prompts_titles),\n",
    "            sparse.coo_matrix(cosine_scores_train_prompts_questions),\n",
    "            sparse.coo_matrix(X_train[features].to_numpy()),\n",
    "        ))\n",
    "        X_val = sparse.hstack((\n",
    "            val_summaries_vectors,\n",
    "            sparse.coo_matrix(cosine_scores_val_prompts_texts),\n",
    "            sparse.coo_matrix(cosine_scores_val_prompts_titles),\n",
    "            sparse.coo_matrix(cosine_scores_val_prompts_questions),\n",
    "            sparse.coo_matrix(X_val[features].to_numpy()),\n",
    "        ))\n",
    "\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_train, y_train_scaled)\n",
    "        y_train_pred_scaled = model.predict(X_train)\n",
    "        y_val_pred_scaled = model.predict(X_val)\n",
    "\n",
    "        y_train_pred = y_scaler.inverse_transform(y_train_pred_scaled)\n",
    "        y_val_pred = y_scaler.inverse_transform(y_val_pred_scaled)\n",
    "\n",
    "        train_mse = mean_squared_error(y_train_pred, y_train)\n",
    "        val_mse = mean_squared_error(y_val_pred, y_val)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Train MSE for {target}: {train_mse_content:.3f}, Val MSE for {target}: {val_mse_content:.3f}\")\n",
    "            \n",
    "        metrics_lists['train'].append(train_mse)\n",
    "        metrics_lists['val'].append(val_mse)\n",
    "    \n",
    "    metrics_avgs = {name: sum(metrics_list)/len(metrics_list) for name, metrics_list in metrics_lists.items()}\n",
    "    return metrics_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
